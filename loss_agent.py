import numpy as np
import json
from groq import Groq
from dotenv import load_dotenv
from loss_after_new_load import get_total_loss_matlab
import os

load_dotenv()

client = Groq()
MODEL = "openai/gpt-oss-120b"

def run_conversation(user_prompt):
    # Initialize the conversation with system and user messages
    messages=[
        {
            "role": "system",
            "content": "You are a power system loss calculator assistant. Use the get_total_loss_matlab function to compute total system losses given the Ybus matrix, voltage profile, new load value and bus location. Parse the user's input into the required structured format for the tool call. At the end add a disclaimer that it's generated by LLM and might not be correct so take it with a pinch of salt."
        },
        {
            "role": "user",
            "content": user_prompt,
        }
    ]
    
    # Define the available tools for our model to use
    tools = [
        {
            "type": "function",
            "function": {
                "name": "get_total_loss_matlab",
                "description": "Calculate total system power loss after adding a new load",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "ybus_np": {
                            "type": "array",
                            "description": "The admittance matrix Ybus as a list of lists of objects with real and imag parts",
                            "items": {
                                "type": "array",
                                "items": {
                                    "type": "object",
                                    "properties": {
                                        "real": {
                                            "type": "number"
                                        },
                                        "imag": {
                                            "type": "number"
                                        }
                                    },
                                    "required": ["real", "imag"]
                                }
                            }
                        },
                        "v_np": {
                            "type": "array",
                            "description": "The voltage vector as a list of objects with real and imag parts",
                            "items": {
                                "type": "object",
                                "properties": {
                                    "real": {
                                        "type": "number"
                                    },
                                    "imag": {
                                        "type": "number"
                                    }
                                },
                                "required": ["real", "imag"]
                            }
                        },
                        "new_load": {
                            "type": "object",
                            "description": "The new load value as complex number with real and imag parts",
                            "properties": {
                                "real": {
                                    "type": "number"
                                },
                                "imag": {
                                    "type": "number"
                                }
                            },
                            "required": ["real", "imag"]
                        },
                        "bus_at_py": {
                            "type": "integer",
                            "description": "The 0-based index of the bus where new load is added"
                        }
                    },
                    "required": ["ybus_np", "v_np", "new_load", "bus_at_py"]
                }
            }
        }
    ]

    # Make the initial API call to Groq
    response = client.chat.completions.create(
        model=MODEL,
        messages=messages,
        stream=False,
        tools=tools,
        tool_choice="auto",
        max_tokens=8100
    )

    # Extract the response and any tool calls
    response_message = response.choices[0].message
    tool_calls = response_message.tool_calls

    if tool_calls:
        # Define helper functions to parse structured args to numpy arrays
        def parse_complex_dict(d):
            return complex(d['real'], d['imag'])
        
        def parse_vector(vec):
            return np.array([parse_complex_dict(item) for item in vec], dtype=complex)
        
        def parse_matrix(mat):
            return np.array([[parse_complex_dict(item) for item in row] for row in mat], dtype=complex)

        # Define available tools
        available_functions = {
            "get_total_loss_matlab": get_total_loss_matlab,
        }

        # Add the LLM's response to conversation
        messages.append(response_message)

        # Process each tool call
        for tool_call in tool_calls:
            function_name = tool_call.function.name
            function_to_call = available_functions[function_name]
            function_args = json.loads(tool_call.function.arguments)
            
            # Parse arguments
            ybus_parsed = parse_matrix(function_args.get("ybus_np"))
            v_parsed = parse_vector(function_args.get("v_np"))
            new_load = parse_complex_dict(function_args.get("new_load"))
            bus_at = function_args.get("bus_at_py")

            # Call the tool and get response
            function_response = function_to_call(
                ybus_np=ybus_parsed,
                v_np=v_parsed,
                new_load=new_load,
                bus_at_py=bus_at
            )

            # Convert response to string
            function_response = str(function_response)

            # Add tool response to conversation
            messages.append(
                {
                    "tool_call_id": tool_call.id,
                    "role": "tool",
                    "name": function_name,
                    "content": function_response,
                }
            )

        # Make second API call with updated conversation
        second_response = client.chat.completions.create(
            model=MODEL,
            messages=messages
        )
        
        # Return final response
        return second_response.choices[0].message.content
    else:
        return response_message.content

# Example usage
if __name__ == "__main__":
    user_input = input("Provide Ybus matrix, voltage vector, new load value and bus number (e.g., 'Ybus: [[1-1j, -1+1j], [-1+1j, 1-1j]], V: [1.0+0j, 0.95-0.0828j], Load: 1.0+0.5j, Bus: 1'): ")
    print(run_conversation(user_input))

def run_loss_agent(user_prompt):
    """
    Wrapper function for orchestrator compatibility
    """
    return run_conversation(user_prompt)